name: Notify New Articles via FCM

on:
  workflow_run:
    workflows: ["Deploy Hugo site to Pages"]
    types:
      - completed
  workflow_dispatch:
    inputs:
      test_mode:
        description: 'Run in test mode'
        required: false
        default: false
        type: boolean

jobs:
  detect-and-notify:
    runs-on: ubuntu-latest
    
    steps:
    - name: 🔄 Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 2  # Fetch last 2 commits to compare
    
    - name: 🔍 Detect new articles
      id: detect_new
      run: |
        echo "🔍 Checking for new articles..."
        
        # Get changed files in the push (both added and modified)
        NEW_MARKDOWN=$(git diff --name-only --diff-filter=AM HEAD~1 HEAD | grep -E '^content/noticias/.*\.md$' || true)
        NEW_SEASON_FILES=$(git diff --name-only --diff-filter=AM HEAD~1 HEAD | grep -E '^data/season_.*\.json$' || true)
        
        # Debug: Show what git diff found
        echo "🔍 Files detected by git diff:"
        git diff --name-only --diff-filter=AM HEAD~1 HEAD || echo "No files detected by git diff"
        
        # Debug: Show filtered results
        echo "🔍 Filtered markdown files (noticias):"
        echo "$NEW_MARKDOWN" || echo "No markdown files found"
        echo "🔍 Filtered season JSON files (podcasts):"
        echo "$NEW_SEASON_FILES" || echo "No season JSON files found"
        
        if [ -z "$NEW_MARKDOWN" ] && [ -z "$NEW_SEASON_FILES" ]; then
          echo "ℹ️ No new articles or podcast episodes detected"
          echo "has_new_articles=false" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        # Process articles
        ARTICLES_JSON="[]"
        
        # Install yq for robust YAML parsing
        sudo wget -qO /usr/local/bin/yq https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64
        sudo chmod +x /usr/local/bin/yq
        
        # Process markdown files (noticias)
        if [ -n "$NEW_MARKDOWN" ]; then
          echo "🆕 New markdown articles detected:"
          echo "$NEW_MARKDOWN"
          
          for file in $NEW_MARKDOWN; do
            if [ -f "$file" ]; then
              echo "📄 Processing: $file"
              
              # Extract frontmatter from markdown file (everything between --- lines)
              FRONTMATTER=$(sed -n '/^---$/,/^---$/p' "$file" | sed '1d;$d')
              
              # Extract fields from frontmatter
              TITLE=$(echo "$FRONTMATTER" | yq '.title' 2>/dev/null | sed 's/^null$//' || echo "New Article")
              DATE=$(echo "$FRONTMATTER" | yq '.date' 2>/dev/null | sed 's/^null$//' || echo "")
              AUTHOR=$(echo "$FRONTMATTER" | yq '.author' 2>/dev/null | sed 's/^null$//' || echo "Mundo Dolphins")
              
              # Generate URL from filename
              FILENAME=$(basename "$file" .md)
              SECTION="noticias"
              URL="https://mundodolphins.es/${SECTION}/${FILENAME}/"
              
              # Create JSON object for this article
              ARTICLE_JSON=$(jq -n \
                --arg title "$TITLE" \
                --arg url "$URL" \
                --arg author "$AUTHOR" \
                --arg date "$DATE" \
                --arg section "$SECTION" \
                '{title: $title, url: $url, author: $author, date: $date, section: $section}')
              
              # Add to articles array
              ARTICLES_JSON=$(echo "$ARTICLES_JSON" | jq ". + [$ARTICLE_JSON]")
              
              echo "✅ Article processed: $TITLE"
              echo "🔗 URL: $URL"
            else
              echo "⚠️ File not found: $file"
            fi
          done
        fi
        
        # Process podcast episodes from season JSON files
        if [ -n "$NEW_SEASON_FILES" ]; then
          echo "🆕 New podcast episodes detected in season files:"
          echo "$NEW_SEASON_FILES"
          
          for file in $NEW_SEASON_FILES; do
            if [ -f "$file" ]; then
              echo "📄 Processing: $file"
              
              # Get the diff and extract only the new episodes (lines that start with +)
              # We'll look for complete JSON objects that were added
              NEW_EPISODES=$(git diff HEAD~1 HEAD -- "$file" | grep '^\+' | grep -v '^\+\+\+' | sed 's/^\+//' || true)
              
              if [ -n "$NEW_EPISODES" ]; then
                # Try to extract complete episode objects from the diff
                # Episodes in the JSON have specific structure with title, link, dateAndTime
                TEMP_JSON=$(mktemp)
                echo "$NEW_EPISODES" > "$TEMP_JSON"
                
                # Parse the new content to find episode objects
                # Since this is a diff, we need to reconstruct the JSON object
                # Let's get the current file and find episodes by date that are new
                
                # Get episodes from current version
                CURRENT_EPISODES=$(jq -c '.[]' "$file" 2>/dev/null || echo "")
                
                # Get episodes from previous version
                PREVIOUS_EPISODES=$(git show HEAD~1:"$file" 2>/dev/null | jq -c '.[]' 2>/dev/null || echo "")
                
                # Find episodes that are in current but not in previous
                # Store previous episodes in a temp file for comparison
                TEMP_PREV=$(mktemp)
                echo "$PREVIOUS_EPISODES" > "$TEMP_PREV"
                
                while IFS= read -r episode; do
                  if [ -n "$episode" ]; then
                    # Extract episode details for matching
                    TITLE=$(echo "$episode" | jq -r '.title')
                    DATE=$(echo "$episode" | jq -r '.dateAndTime')
                    LINK=$(echo "$episode" | jq -r '.link')
                    
                    # Create a unique identifier for exact matching
                    EPISODE_ID="${TITLE}|${DATE}|${LINK}"
                    
                    # Search for exact match in previous version
                    FOUND=""
                    while IFS= read -r prev_episode; do
                      if [ -n "$prev_episode" ]; then
                        PREV_TITLE=$(echo "$prev_episode" | jq -r '.title')
                        PREV_DATE=$(echo "$prev_episode" | jq -r '.dateAndTime')
                        PREV_LINK=$(echo "$prev_episode" | jq -r '.link')
                        PREV_ID="${PREV_TITLE}|${PREV_DATE}|${PREV_LINK}"
                        
                        if [ "$EPISODE_ID" = "$PREV_ID" ]; then
                          FOUND="yes"
                          break
                        fi
                      fi
                    done < "$TEMP_PREV"
                    
                    if [ -z "$FOUND" ]; then
                      echo "🎙️ New podcast episode found: $TITLE"
                      
                      # Create article JSON object
                      ARTICLE_JSON=$(jq -n \
                        --arg title "$TITLE" \
                        --arg url "$LINK" \
                        --arg author "Mundo Dolphins" \
                        --arg date "$DATE" \
                        --arg section "podcast" \
                        '{title: $title, url: $url, author: $author, date: $date, section: $section}')
                      
                      # Add to articles array
                      ARTICLES_JSON=$(echo "$ARTICLES_JSON" | jq ". + [$ARTICLE_JSON]")
                      
                      echo "✅ Podcast episode processed: $TITLE"
                      echo "🔗 URL: $LINK"
                    fi
                  fi
                done < <(echo "$CURRENT_EPISODES")
                
                rm -f "$TEMP_PREV"
                
                rm -f "$TEMP_JSON"
              fi
            else
              echo "⚠️ File not found: $file"
            fi
          done
        fi
        
        ARTICLE_COUNT=$(echo "$ARTICLES_JSON" | jq length)
        if [ "$ARTICLE_COUNT" -eq 0 ]; then
          echo "ℹ️ No new content detected after processing"
          echo "has_new_articles=false" >> $GITHUB_OUTPUT
          exit 0
        fi
        
        echo "has_new_articles=true" >> $GITHUB_OUTPUT
        echo "articles_count=$ARTICLE_COUNT" >> $GITHUB_OUTPUT
        
        # Save articles data for next step
        echo "$ARTICLES_JSON" > articles.json
        echo "📊 Articles JSON content:"
        cat articles.json
    
    - name: 🔔 Send FCM notifications
      if: steps.detect_new.outputs.has_new_articles == 'true'
      env:
        FIREBASE_PROJECT_ID: ${{ secrets.FIREBASE_PROJECT_ID }}
        FIREBASE_PRIVATE_KEY: ${{ secrets.FIREBASE_PRIVATE_KEY }}
        FIREBASE_CLIENT_EMAIL: ${{ secrets.FIREBASE_CLIENT_EMAIL }}
        FCM_TOPIC: ${{ secrets.FCM_TOPIC || 'mundo-dolphins-news' }}
        NOTIFICATION_DELAY_MS: ${{ vars.NOTIFICATION_DELAY_MS || '1000' }}
      run: |
        echo "🔔 Sending FCM notifications..."
        npm init -y
        npm install firebase-admin
        cat > send_notification.js << 'EOF'
        const admin = require('firebase-admin');
        const fs = require('fs');

        // Configuration constants
        const DEFAULT_NOTIFICATION_DELAY_MS = 1000; // Default delay between notifications in ms
        // Regex to validate base64 (allows newlines, whitespace, padding)
        const BASE64_REGEX = /^[A-Za-z0-9+/=\s\r\n]+$/;

        // Validation constants
        const VALIDATION_CONSTANTS = {
          HARD_MIN_PRIVATE_KEY_LENGTH: 344,
          MIN_PRIVATE_KEY_LENGTH: Math.max(
            process.env.MIN_PRIVATE_KEY_LENGTH
              ? parseInt(process.env.MIN_PRIVATE_KEY_LENGTH, 10)
              : 344,
            344
          )
        };

        // Runtime configuration
        const NOTIFICATION_CONFIG = {
          NOTIFICATION_DELAY_MS: parseInt(process.env.NOTIFICATION_DELAY_MS, 10) || DEFAULT_NOTIFICATION_DELAY_MS
        };

        // Validate and process private key
        function validateAndProcessPrivateKey(privateKey) {
          if (!privateKey) {
            throw new Error('FIREBASE_PRIVATE_KEY environment variable is not set');
          }
          let processedKey = privateKey.includes('\\n') 
            ? privateKey.replace(/\\n/g, '\n')
            : privateKey;
          if (!processedKey.includes('-----BEGIN PRIVATE KEY-----') || 
              !processedKey.includes('-----END PRIVATE KEY-----')) {
            throw new Error('Invalid private key format. Key must include BEGIN and END markers.');
          }
          const keyContent = processedKey
            .replace('-----BEGIN PRIVATE KEY-----', '')
            .replace('-----END PRIVATE KEY-----', '')
            .replace(/\s/g, '');
          if (keyContent.length < VALIDATION_CONSTANTS.MIN_PRIVATE_KEY_LENGTH) {
            throw new Error('Private key appears to be too short or malformed');
          }
          try {
            if (!BASE64_REGEX.test(keyContent)) {
              throw new Error('Private key content does not appear to be valid base64');
            }
            Buffer.from(keyContent, 'base64');
          } catch (base64Error) {
            throw new Error('Private key base64 validation failed: ' + base64Error.message);
          }
          return processedKey;
        }

        // Initialize Firebase Admin
        const serviceAccount = {
          type: "service_account",
          project_id: process.env.FIREBASE_PROJECT_ID,
          private_key: validateAndProcessPrivateKey(process.env.FIREBASE_PRIVATE_KEY),
          client_email: process.env.FIREBASE_CLIENT_EMAIL,
        };

        admin.initializeApp({
          credential: admin.credential.cert(serviceAccount),
          projectId: process.env.FIREBASE_PROJECT_ID
        });

        async function sendNotifications() {
          try {
            const articles = JSON.parse(fs.readFileSync('articles.json', 'utf8'));
            const topic = process.env.FCM_TOPIC;
            console.log(`📤 Sending notifications for ${articles.length} article(s) to topic: ${topic}`);
            for (let i = 0; i < articles.length; i++) {
              const article = articles[i];
              const message = {
                topic: topic,
                notification: {
                  title: '🐬 Nuevo en Mundo Dolphins',
                  body: article.title
                },
                data: {
                  url: article.url,
                  title: article.title,
                  author: article.author,
                  section: article.section,
                  timestamp: new Date().toISOString()
                },
                android: {
                  notification: {
                    icon: 'ic_notification',
                    color: '#008B8B',
                    clickAction: article.url
                  }
                },
                webpush: {
                  notification: {
                    icon: '/favicon-192x192.png',
                    badge: '/favicon-96x96.png',
                    tag: 'mundo-dolphins-article',
                    requireInteraction: true,
                    actions: [
                      {
                        action: 'read',
                        title: 'Leer artículo',
                        icon: '/favicon-96x96.png'
                      }
                    ]
                  },
                  fcmOptions: {
                    link: article.url
                  }
                }
              };
              console.log(`📨 Sending notification for: "${article.title}"`);
              console.log(`🔗 URL: ${article.url}`);
              const response = await admin.messaging().send(message);
              console.log(`✅ Notification sent successfully: ${response}`);
              if (i < articles.length - 1 && NOTIFICATION_CONFIG.NOTIFICATION_DELAY_MS > 0) {
                await new Promise(resolve => setTimeout(resolve, NOTIFICATION_CONFIG.NOTIFICATION_DELAY_MS));
              }
            }
            console.log('🎉 All notifications sent successfully!');
          } catch (error) {
            console.error('❌ Error sending notifications:', error);
            process.exit(1);
          }
        }
        sendNotifications();
        EOF
        node send_notification.js